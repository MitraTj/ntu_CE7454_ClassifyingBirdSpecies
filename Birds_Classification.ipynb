{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Bird Species in Singapore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Singapore is a vibrant tropical country that, in spite of its urbanization, offers a paradise for nature lovers. In particular, its nature reserves are home to a host of different species of birds, attracting birdwatchers, nature enthusiasts and simple weekend hikers from all over the world. The official website of [Singapore's National Parks](https://www.nparks.gov.sg/biodiversity/wildlife-in-singapore/species-list/bird) catalogs over 400 different bird species that can be found on the island. Thus it happens frequently to take an image or see a bird flying in the wild without being able to recognize the species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We construct our dataset by empploying webscrapers on websites such as [Flickr](./from_flickr_to_dataset.ipynb) and [Internet Bird Collection](./scraper_ibc.ipynb) to crawl publicly available images of the common bird species in Singapore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display_html\n",
    "import itertools\n",
    "import keras_preprocessing.image\n",
    "from collections import defaultdict\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from tensorflow.python.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, BatchNormalization, Input, Dropout, Lambda\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# The following resolves the issue of possibly truncated images in the datasets\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Augmentation\n",
    "Next we proceed with the preprocessing of the raw images.\n",
    "\n",
    "This involves the following:\n",
    "\n",
    "1. A [web application](http://172.21.144.45:5000/) is developed enabling users to manually remove noisy images from the raw dataset. Examples of noisy images are\n",
    " - Image does not correspond to the bird species\n",
    " - Too much sightline occlusion\n",
    " - More than 1 bird present\n",
    "\n",
    "2. Remove bird species with fewer than 50 images\n",
    "\n",
    "3. Data normalization and augmentation.\n",
    "\n",
    "For (2) and (3), we employ the Keras API. Dataframes are created for the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all data folders for the raw images\n",
    "data_folders = [f for f in os.scandir('data') if f.is_dir()]\n",
    "nspecies = len(data_folders)\n",
    "\n",
    "train_ratio = 0.8\n",
    "\n",
    "train_paths = []\n",
    "\n",
    "test_paths = []\n",
    "\n",
    "# Create dataframes that can be used directly by Keras ImageDataGenerator class\n",
    "for i in range(nspecies):\n",
    "    image_list = glob(data_folders[i].path + \"/*.jpg\")\n",
    "\n",
    "    # Remove datasets with fewer than 50 images\n",
    "    if len(image_list)<50:\n",
    "        continue\n",
    "\n",
    "    # Splitting the datasets to training and testing\n",
    "    train_idx = math.floor(len(image_list)*train_ratio)\n",
    "    for j in range(train_idx):\n",
    "        train_paths.append(image_list[j][5:])\n",
    "    for j in range(train_idx,len(image_list)):\n",
    "        test_paths.append(image_list[j][5:])\n",
    "train_set = pd.DataFrame({'paths':train_paths})\n",
    "test_set = pd.DataFrame({'paths':test_paths})\n",
    "\n",
    "# The clean dataset is obtained by manual cleaning\n",
    "dataset_clean = pd.read_csv('./dataset_clean.csv')\n",
    "\n",
    "train_set = pd.merge(train_set, dataset_clean, how='inner', on=['paths'])\n",
    "test_set = pd.merge(test_set, dataset_clean, how='inner', on=['paths'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we list the amount of training and testing images for each species\n",
    "train_distribution = train_set.groupby(['species'], as_index=False).count()\n",
    "train_distribution.drop(train_distribution.columns.difference(['species','paths']), 1, inplace=True)\n",
    "train_distribution.columns=['species', '# Train Images']\n",
    "train_distribution\n",
    "\n",
    "test_distribution = test_set.groupby(['species'], as_index=False).count()\n",
    "test_distribution.drop(test_distribution.columns.difference(['species','paths']), 1, inplace=True)\n",
    "test_distribution.columns=['species', '# Test Images']\n",
    "test_distribution\n",
    "\n",
    "species_info = pd.merge(train_distribution,test_distribution)\n",
    "display(species_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all images belonging to a species\n",
    "def read_images(species, trainortest):\n",
    "    if trainortest == 'train':\n",
    "        paths = train_set['paths'][train_set['species']==species].tolist()\n",
    "    elif trainortest == 'test':\n",
    "        paths = test_set['paths'][test_set['species']==species].tolist()\n",
    "    paths = ['./data/' + s for s in paths]\n",
    "    imgs = [load_img(img_path, target_size=(image_size, image_size)) for img_path in paths]\n",
    "    img_array = np.array([img_to_array(img) for img in imgs])\n",
    "    return img_array\n",
    "\n",
    "\n",
    "# Visualize images from a species\n",
    "all_species = train_set.species.unique()\n",
    "species = all_species[0]\n",
    "\n",
    "imgs = read_images(species, 'train')/255\n",
    "n_imgs = imgs.shape[0]\n",
    "columns = 4\n",
    "fig = plt.figure(figsize=(20,int(n_imgs/columns*5)))\n",
    "for i in range(n_imgs):\n",
    "    plt.subplot(n_imgs/columns+1, columns, i + 1)\n",
    "    plt.imshow(imgs[i])\n",
    "    plt.axis('off')\n",
    "plt.suptitle(species.upper(), fontsize='x-large')\n",
    "fig.tight_layout\n",
    "fig.subplots_adjust(top=0.97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Proposed Classification Pipeline\n",
    "\n",
    "Feature extraction will be done using the ResNet50 network pretrained on ImageNet.\n",
    "\n",
    "Following feature extraction, we then train our network for classification over the bird species. For this task, we adopt and compare the classification performance of two loss functions.\n",
    "\n",
    "-  Softmax entropy loss which is commonly used in classification tasks.\n",
    "-  Triplet loss (an example of a loss function from the metric learning loss class)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classification\n",
    "\n",
    "In the following, we employ the Keras preprocessing framework to read in the training and testing datasets defined via the dataframes above. Keras also allows us to perform data augmentation efficiently.\n",
    "\n",
    "\n",
    "**If the following error arises**, update your Keras package.\n",
    "\n",
    "*ImageDataGenerator' object has no attribute 'flow_from_dataframe'*\n",
    "\n",
    "**Also take note that we do not implement rescale=1./255 here to be consistent with ResNet50 preprocessing. Otherwise, there will be issues when evaluating the trained model on the test set.** This [link](https://github.com/keras-team/keras/issues/3477) discusses a similar issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some hyperparameters\n",
    "image_size = 224\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Patch the dataframe filenames interaction in Keras preprocessing\n",
    "def patched_list_filenames(directory, white_list_formats, split,\n",
    "                                       class_indices, follow_links, df=False):\n",
    "    dirname = os.path.basename(directory)\n",
    "    if split:\n",
    "        num_files = len(list(\n",
    "            _iter_valid_files(directory, white_list_formats, follow_links)))\n",
    "        start, stop = int(split[0] * num_files), int(split[1] * num_files)\n",
    "        valid_files = list(\n",
    "            _iter_valid_files(\n",
    "                directory, white_list_formats, follow_links))[start: stop]\n",
    "    else:\n",
    "        valid_files = _iter_valid_files(\n",
    "            directory, white_list_formats, follow_links)\n",
    "    if df:\n",
    "        filenames = []\n",
    "        for root, fname in valid_files:\n",
    "            absolute_path = os.path.join(root, fname)\n",
    "            relative_path = os.path.relpath(absolute_path, directory)\n",
    "            filenames.append(relative_path)\n",
    "        return filenames\n",
    "    classes = []\n",
    "    filenames = []\n",
    "    for root, fname in valid_files:\n",
    "        classes.append(class_indices[dirname])\n",
    "        absolute_path = os.path.join(root, fname)\n",
    "        relative_path = os.path.join(\n",
    "            dirname, os.path.relpath(absolute_path, directory))\n",
    "        filenames.append(relative_path)\n",
    "    return classes, filenames\n",
    "\n",
    "keras_preprocessing.image._list_valid_filenames_in_directory.__code__ = patched_list_filenames.__code__\n",
    "\n",
    "\n",
    "# Train set generation and augmentation using Keras preprocessing\n",
    "softmax_train_gen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                     width_shift_range = 0.4,\n",
    "                                     height_shift_range = 0.4,\n",
    "                                     zoom_range=0.3,\n",
    "                                     rotation_range=20,\n",
    "                                    )\n",
    "softmax_train_gen = softmax_train_gen.flow_from_dataframe(\n",
    "    dataframe=train_set, \n",
    "    directory='./data',\n",
    "    x_col='paths', \n",
    "    y_col='species', \n",
    "    has_ext=True,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "# Test set generation using Keras preprocessing\n",
    "softmax_test_gen = ImageDataGenerator()\n",
    "softmax_test_gen = softmax_test_gen.flow_from_dataframe(\n",
    "    dataframe=test_set, \n",
    "    directory=\"./data/\", \n",
    "    x_col=\"paths\", \n",
    "    y_col=\"species\", \n",
    "    has_ext=True,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "num_classes = len(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax classification network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained ResNet50 on ImageNet\n",
    "softmax_model = Sequential()\n",
    "\n",
    "softmax_model.add(ResNet50(include_top=False, pooling='avg', weights='imagenet'))\n",
    "softmax_model.add(Flatten())\n",
    "softmax_model.add(BatchNormalization())\n",
    "softmax_model.add(Dense(2048, activation='relu'))\n",
    "softmax_model.add(BatchNormalization())\n",
    "softmax_model.add(Dense(1024, activation='relu'))\n",
    "softmax_model.add(BatchNormalization())\n",
    "softmax_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "softmax_model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return tf.keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[top_3_accuracy])\n",
    "\n",
    "softmax_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "hist = model.fit_generator(generator=softmax_train_gen,\n",
    "                           steps_per_epoch=int(train_set.shape[0]/batch_size)+1,\n",
    "                           epochs=10,\n",
    "                           shuffle=True,\n",
    "                           validation_data=softmax_test_gen,\n",
    "                           validation_steps=int(test_set.shape[0]/batch_size)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on Test Images\n",
    "\n",
    "We evaluate on test images and display the results using a confusion matrix and precision/recall/f1-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test_images(family):\n",
    "    paths = test_set['paths'][test_set['family']==family].tolist()\n",
    "    paths = ['./data/' + s for s in paths]\n",
    "    imgs = [load_img(img_path, target_size=(image_size, image_size)) for img_path in paths]\n",
    "    img_array = np.array([img_to_array(img) for img in imgs])\n",
    "    return preprocess_input(img_array)\n",
    "\n",
    "prediction_results = []\n",
    "ground_truth = []\n",
    "test_distribution.to_dict()\n",
    "for i in range(len(families)):\n",
    "    prediction_results.append(model.predict_classes(read_test_images(families[i])))\n",
    "    n_test_imgs = test_distribution.loc[test_distribution['family']==families[i]].iloc[0][1]\n",
    "    ground_truth.append(np.ones(n_test_imgs)*i)\n",
    "prediction_results = np.hstack(prediction_results)\n",
    "ground_truth = np.hstack(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion Matrix')\n",
    "CM = confusion_matrix(ground_truth, prediction_results)\n",
    "print(CM)\n",
    "target_names = [families[i] for i in range(len(families))]\n",
    "print('Classification Report')\n",
    "CR = classification_report(ground_truth, prediction_results, target_names=target_names)\n",
    "print(CR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triplet loss classification\n",
    "\n",
    "The triplet loss is an example of a metric learning loss. The goal is to learn a metric function that maps from the base features extracted using the pretrained ResNet50 to a target embedding vector. This mapping minimizes intra-species distances while maximizing inter-species distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some hyperparameters\n",
    "image_size = 224\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "class sample_gen(object):\n",
    "    def __init__(self, file_class_mapping):\n",
    "        self.file_class_mapping= file_class_mapping\n",
    "        self.class_to_list_files = defaultdict(list)\n",
    "        self.list_all_files = list(file_class_mapping.keys())\n",
    "        self.range_all_files = list(range(len(self.list_all_files)))\n",
    "\n",
    "        for file, class_ in file_class_mapping.items():\n",
    "            self.class_to_list_files[class_].append(file)\n",
    "\n",
    "        self.list_classes = list(set(self.file_class_mapping.values()))\n",
    "        self.range_list_classes= range(len(self.list_classes))\n",
    "        self.class_weight = np.array([len(self.class_to_list_files[class_]) for class_ in self.list_classes])\n",
    "        self.class_weight = self.class_weight/np.sum(self.class_weight)\n",
    "\n",
    "    def get_sample(self):\n",
    "        class_idx = np.random.choice(self.range_list_classes, 1, p=self.class_weight)[0]\n",
    "        examples_class_idx = np.random.choice(range(len(self.class_to_list_files[self.list_classes[class_idx]])), 2)\n",
    "        anchor_example, positive_example = self.class_to_list_files[self.list_classes[class_idx]][examples_class_idx[0]], self.class_to_list_files[self.list_classes[class_idx]][examples_class_idx[1]]\n",
    "\n",
    "        negative_example = None\n",
    "        while negative_example is None or self.file_class_mapping[negative_example] == self.file_class_mapping[anchor_example]:\n",
    "            negative_example_idx = np.random.choice(self.range_all_files, 1)[0]\n",
    "            negative_example = self.list_all_files[negative_example_idx]\n",
    "        return anchor_example, positive_example,negative_example\n",
    "\n",
    "    \n",
    "def read_single_image(img_path):\n",
    "    img = load_img('./data/' + img_path, target_size=(image_size, image_size))\n",
    "    img_array = np.array(img_to_array(img))\n",
    "    return preprocess_input(img_array)\n",
    "\n",
    "\n",
    "def gen(triplet_gen):\n",
    "    while True:\n",
    "        list_anchor = []\n",
    "        list_negative = []\n",
    "        list_positive = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            path_anchor, path_positive, path_negative = triplet_gen.get_sample()\n",
    "            \n",
    "            anchor = read_single_image(path_anchor)\n",
    "            positive = read_single_image(path_positive)\n",
    "            negative = read_single_image(path_negative)\n",
    "\n",
    "            list_anchor.append(anchor)\n",
    "            list_positive.append(positive)\n",
    "            list_negative.append(negative)\n",
    "\n",
    "        A = preprocess_input(np.array(list_anchor))\n",
    "        P = preprocess_input(np.array(list_positive))\n",
    "        N = preprocess_input(np.array(list_negative))\n",
    "        \n",
    "        yield ({'anchor_input': A, 'positive_input': P, 'negative_input': N}, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(inputs, dist='sqeuclidean', margin='maxplus'):\n",
    "    anchor, positive, negative = inputs\n",
    "    positive_distance = K.square(anchor - positive)\n",
    "    negative_distance = K.square(anchor - negative)\n",
    "    if dist == 'euclidean':\n",
    "        positive_distance = K.sqrt(K.sum(positive_distance, axis=-1, keepdims=True))\n",
    "        negative_distance = K.sqrt(K.sum(negative_distance, axis=-1, keepdims=True))\n",
    "    elif dist == 'sqeuclidean':\n",
    "        positive_distance = K.sum(positive_distance, axis=-1, keepdims=True)\n",
    "        negative_distance = K.sum(negative_distance, axis=-1, keepdims=True)\n",
    "    loss = positive_distance - negative_distance\n",
    "    if margin == 'maxplus':\n",
    "        loss = K.maximum(0.0, 1 + loss)\n",
    "    elif margin == 'softplus':\n",
    "        loss = K.log(1 + K.exp(loss))\n",
    "    return K.mean(loss)\n",
    "\n",
    "\n",
    "embedding_dim = 50\n",
    "def GetModel():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, pooling='max')\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = Dropout(0.6)(x)\n",
    "    x = Dense(embedding_dim)(x)\n",
    "    x = Lambda(lambda  x: K.l2_normalize(x,axis=1))(x)\n",
    "    embedding_model = Model(base_model.input, x, name=\"embedding\")\n",
    "\n",
    "    input_shape = (image_size, image_size, 3)\n",
    "    anchor_input = Input(input_shape, name='anchor_input')\n",
    "    positive_input = Input(input_shape, name='positive_input')\n",
    "    negative_input = Input(input_shape, name='negative_input')\n",
    "    anchor_embedding = embedding_model(anchor_input)\n",
    "    positive_embedding = embedding_model(positive_input)\n",
    "    negative_embedding = embedding_model(negative_input)\n",
    "\n",
    "    inputs = [anchor_input, positive_input, negative_input]\n",
    "    outputs = [anchor_embedding, positive_embedding, negative_embedding]\n",
    "       \n",
    "    triplet_model = Model(inputs, outputs)\n",
    "    triplet_model.add_loss(K.mean(triplet_loss(outputs)))\n",
    "\n",
    "    return embedding_model, triplet_model\n",
    "\n",
    "\n",
    "embedding_model, triplet_model = GetModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths_species = {img_path: species for img_path, species in zip(train_set.paths, train_set.species)}\n",
    "train_paths_species = sample_gen(train_paths_species)\n",
    "triplet_train_gen = gen(train_paths_species)\n",
    "\n",
    "test_paths_species = {img_path: species for img_path, species in zip(test_set.paths, test_set.species)}\n",
    "test_paths_species = sample_gen(test_paths_species)\n",
    "triplet_test_gen = gen(test_paths_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_model.compile(loss=None, optimizer='adam')\n",
    "history = triplet_model.fit_generator(triplet_train_gen,\n",
    "                              epochs=5,\n",
    "                              steps_per_epoch=train_set.shape[0]//batch_size,\n",
    "                              validation_data=triplet_test_gen, \n",
    "                              validation_steps=test_set.shape[0]//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on Test Images\n",
    "\n",
    "We evaluate on test images and display the results using a confusion matrix and precision/recall/f1-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(species, trainortest):\n",
    "    if trainortest == 'train':\n",
    "        paths = train_set['paths'][train_set['species']==species].tolist()\n",
    "    elif trainortest == 'test':\n",
    "        paths = test_set['paths'][test_set['species']==species].tolist()\n",
    "    paths = ['./data/' + s for s in paths]\n",
    "    imgs = [load_img(img_path, target_size=(image_size, image_size)) for img_path in paths]\n",
    "    img_array = np.array([img_to_array(img) for img in imgs])\n",
    "    return img_array\n",
    "\n",
    "\n",
    "train_features = []\n",
    "for species in all_species:\n",
    "    train_imgs = preprocess_input(read_images(species, 'train'))\n",
    "    train_features.append(embedding_model.predict(train_imgs))\n",
    "    \n",
    "train_features = np.vstack(train_features)\n",
    "\n",
    "\n",
    "test_features = []\n",
    "for species in all_species:\n",
    "    test_imgs = preprocess_input(read_images(species, 'test'))\n",
    "    test_features.append(embedding_model.predict(test_imgs))\n",
    "    \n",
    "test_features = np.vstack(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = NearestNeighbors(n_neighbors=1)\n",
    "neigh.fit(train_features)\n",
    "distances_test, neighbors_test = neigh.kneighbors(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "test_labels = []\n",
    "for i in train_paths_species.list_classes:\n",
    "    nspecies_i = train_distribution['# Train Images'][train_distribution.species==i].iloc[0]\n",
    "    for j in range(nspecies_i):\n",
    "        train_labels.append(i)\n",
    "    \n",
    "    nspecies_i = test_distribution['# Test Images'][train_distribution.species==i].iloc[0]\n",
    "    for j in range(nspecies_i):\n",
    "        test_labels.append(i)\n",
    "\n",
    "predicted_labels = []\n",
    "for i in range(neighbors_test.shape[0]):\n",
    "    predicted_labels.append(train_labels[np.asscalar(neighbors_test[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion Matrix')\n",
    "CM = confusion_matrix(test_labels, predicted_labels)\n",
    "print(CM)\n",
    "print('Classification Report')\n",
    "target_names = [i for i in train_paths_species.list_classes]\n",
    "CR = classification_report(test_labels, predicted_labels, target_names=target_names)\n",
    "print(CR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
